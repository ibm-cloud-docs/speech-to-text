---

copyright:
  years: 2019
lastupdated: "2019-06-24"

subcollection: speech-to-text

---

{:shortdesc: .shortdesc}
{:external: target="_blank" .external}
{:tip: .tip}
{:important: .important}
{:note: .note}
{:deprecated: .deprecated}
{:pre: .pre}
{:codeblock: .codeblock}
{:screen: .screen}
{:javascript: .ph data-hd-programlang='javascript'}
{:java: .ph data-hd-programlang='java'}
{:python: .ph data-hd-programlang='python'}
{:swift: .ph data-hd-programlang='swift'}

# カスタム音響モデルとカスタム言語モデルの併用
{: #useBoth}

補完的なカスタム言語モデルをカスタム音響モデルとともに使用して音声認識の正確度を改善できます。 音響モデルのトレーニングと音声認識で、この両方のタイプのモデルを使用できます。 両方のモデルが同じサービス・インスタンスにより所有されており、同じ基本言語モデルをベースとしている必要があります。
{: shortdesc}

カスタム音響モデルだけを使用することや、トレーニングされていないカスタム言語モデルと共に使用することも、有効な場合があります。 書き起こしする音声に一致する音響特性に関してカスタム音響モデルがトレーニングされると、書き起こしの品質が改善される可能性があります。

## カスタム言語モデルを使用したカスタム音響モデルのトレーニング
{: #useBothTrain}

音声データのみを使用したカスタム音響モデルのトレーニングは*教師なし学習*と呼ばれます。 トレーニング中にカスタム言語モデルを使用することは*準教師付き学習*と呼ばれます。 準教師付き学習により、カスタム音響モデルの有効性を改善できます。

以下の状況では、準教師付き学習を使用して、カスタム言語モデルでカスタム音響モデルをトレーニングします。

-   カスタム言語モデルが、カスタム音響モデルに追加した音声ファイルからの書き起こし (逐語テキスト) に基づいている。

    書き起こしには音声ファイルの正確な内容が含まれているため、書き起こしに基づくカスタム言語モデルでのトレーニングから最も優れた結果を得られる可能性があります。 サービスでは、コンテキストで書き起こしの内容を解析し、音声を最も効率的に利用するために役立つ OOV 語と n グラムを抽出できます。 このことは特に、音声データが 1 時間未満の場合に該当します。

    音声データの書き起こしは必ずしも必要ではありません。 ただし、音声の書き起こしがあると、カスタム音響モデルの品質が改善される可能性があります。 音声に複数の OOV 語が含まれている場合、書き起こしは特に有用です。
-   カスタム言語モデルが、コーパス (テキスト・ファイル) または音声ファイルのコンテンツに関連する単語のリストをベースにしている。

    音声に、サービスの基本語彙にはない分野固有の単語が含まれている場合、音響モデルをカスタマイズするだけでは、書き起こし中にこれらの単語は生成されません。 サービスの基本語彙を拡張する唯一の方法は、言語モデルのカスタマイズです。 書き起こしがない場合は、音声データと同じ分野の OOV 語を含むカスタム言語モデルでトレーニングします。 音声で使用されている OOV 語のリストを含むカスタム言語モデルでトレーニングすることも、有効である場合があります。

    例えば、特定の製品に関するコールセンターの音声に基づくカスタム音響モデルを作成するとします。 関連コールの書き起こしに基づくカスタム言語モデル、またはコール・センターが扱う特定製品の名前を含むカスタム言語モデルを使用してカスタム音響モデルをトレーニングできます。

書き起こしまたは単語リストを使用するには、最初にこのテキスト・データを含むカスタム言語モデルを作成します。 カスタム言語モデルを使用してカスタム音響モデルをトレーニングするには、両方のカスタム・モデルが同じ基本モデルの同じバージョンに基づいている必要があります。 基本モデルの新しいバージョンが利用可能になった場合、トレーニングを成功させるためには、両方のモデルをその基本モデルの同じバージョンにアップグレードする必要があります。

カスタム言語モデルを使用してカスタム音響モデルをトレーニングするには、`POST /v1/acoustic_customizations/{customization_id}/train` メソッドのオプション・クエリー・パラメーター `custom_language_model_id` を使用します。 `customization_id` パラメーターで音響モデルの GUID を渡し、`custom_language_model_id` パラメーターでカスタム言語モデルの GUID を渡します。 両方のモデルが、要求で渡される資格情報により所有されている必要があります。

```bash
curl -X POST -u "apikey:{apikey}"
"https://stream.watsonplatform.net/speech-to-text/api/v1/acoustic_customizations/{customization_id}/train?custom_language_model_id={customization_id}"
```
{: pre}

## 音声認識でのカスタム言語モデルとカスタム音響モデルの使用
{: #useBothRecognize}

認識要求ではカスタム言語モデルとカスタム音響モデルの両方を指定できます。 カスタム言語モデルに、認識される音声の分野の OOV 語が含まれている場合、音声認識でカスタム言語モデルをカスタム音響モデルとともに使用することで、書き起こしの正確度を改善できます。

カスタム言語モデルを使用すると、カスタム音響モデルのトレーニングにカスタム言語モデルを使用したかどうかに関係なく、書き起こしの正確度を改善できます。

-   トレーニングでカスタム言語モデルとカスタム音響モデルの両方を使用すると、カスタム音響モデルの品質が向上します。
-   音声認識で両方のモデルを使用すると、書き起こしの品質が向上します。

カスタム言語モデルに文法が含まれている場合、音声認識でカスタム言語モデルとその文法の 1 つをカスタム音響モデルと共に使用することもできます。

両方のタイプのモデルを HTTP `POST /v1/recognize` メソッドに渡す例を以下に示します。 `acoustic_customization_id` パラメーターでカスタム音響モデルの GUID を渡し、`language_customization_id` パラメーターでカスタム言語モデルの GUID を渡します。 両方のモデルが、要求で渡される資格情報により所有されており、同じ基本モデル (`en-US_BroadbandModel` など) に基づいている必要があります。

```bash
curl -X POST -u "apikey:{apikey}"
--header "Content-Type: audio/flac"
--data-binary @audio-file1.flac
"https://stream.watsonplatform.net/speech-to-text/api/v1/recognize?acoustic_customization_id={customization_id}&language_customization_id={customization_id}"
```
{: pre}

非同期 HTTP 要求の場合、非同期ジョブの作成時にパラメーターを指定します。 WebSockets の場合、接続の確立時にパラメーターを渡します。
