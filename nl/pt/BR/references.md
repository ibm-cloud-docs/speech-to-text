---

copyright:
  years: 2019
lastupdated: "2019-07-03"

subcollection: speech-to-text

---

{:shortdesc: .shortdesc}
{:new_window: target="_blank"}
{:tip: .tip}
{:important: .important}
{:note: .note}
{:deprecated: .deprecated}
{:pre: .pre}
{:codeblock: .codeblock}
{:screen: .screen}
{:javascript: .ph data-hd-programlang='javascript'}
{:java: .ph data-hd-programlang='java'}
{:python: .ph data-hd-programlang='python'}
{:swift: .ph data-hd-programlang='swift'}

# Referências de pesquisa
{: #references}

Para obter mais informações sobre a pesquisa por trás do serviço do {{site.data.keyword.speechtotextfull}}, consulte os documentos a seguir. Os pesquisadores da IBM escreveram ou contribuíram para todos esses documentos.
{: shortdesc}

1.  <a id="audhkhasi2017" style="border-bottom:none">Audhkhasi, Kartik, Bhuvana Ramabhadran, George Saon, Michael Picheny e David Nahamoo.</a> [*Direct Acoustics-to-Word Models for English Conversational Speech Recognition.*](https://www.isca-speech.org/archive/Interspeech_2017/pdfs/0546.PDF){: external} Proceedings of Interspeech 2017 (agosto de 2017): pp. 959-963.
1.  <a id="audhkhasi2018" style="border-bottom:none">Audhkhasi, Kartik, Brian Kingsbury, Bhuvana Ramabhadran, George Saon e Michael Picheny.</a> [*Building competitive direct acoustics-to-word models for English conversational speech recognition.*](https://arxiv.org/pdf/1712.03133.pdf){: external} Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (2018).
1.  <a id="bahl1983" style="border-bottom:none">Bahl, Lalit R., Frederick Jelinek e Robert L. Mercer.</a> [*A Maximum Likelihood Approach to Continuous Speech Recognition.*](http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=4767370&url=http%3A%2F%2Fieeexplore.ieee.org%2Fiel5%2F34%2F4767360%2F04767370.pdf%3Farnumber%3D4767370){: external} IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 5(2) (março de 1983): pp. 179-190.
1.  <a id="fukuda2017" style="border-bottom:none">Fukuda, Takashi, Masayuki Suzuki, Gakuto Kurata, Samuel Thomas, Jia Cui e Bhuvana Ramabhadran.</a> [*Efficient Knowledge Distillation from an Ensemble of Teachers.*](https://www.isca-speech.org/archive/Interspeech_2017/pdfs/0614.PDF){: external} Proceedings of Interspeech 2017 (agosto de 2017): pp. 3697-3701.
1.  <a id="hinton2012" style="border-bottom:none">Hinton, Geoffrey, Li Deng, Dong Yu, George E. Dahl, Abdel-rahman Mohamed, Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N. Sainath e Brian Kingsbury.</a> [*Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups.*](http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6296526){: external} Signal Processing Magazine, IEEE, Vol. 29(6) (novembro de 2012): pp. 82-97.
1.  <a id="jelinek1985" style="border-bottom:none">Jelinek, Frederick.</a> [*The Development of an Experimental Discrete Dictation Recognizer.*](http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=1457611&url=http%3A%2F%2Fieeexplore.ieee.org%2Fiel5%2F5%2F31355%2F01457611.pdf%3Farnumber%3D1457611){: external} Proceedings of the IEEE, Vol. 73(11) (novembro de 1985): pp. 1616-1624.
1.  <a id="kurata2017a" style="border-bottom:none">Kurata, Gakuto, Abhinav Sethy, Bhuvana Ramabhadran e George Saon.</a> [*Empirical Exploration of Novel Architectures and Objectives for Language Models.*](https://www.isca-speech.org/archive/Interspeech_2017/pdfs/0723.PDF){: external} Proceedings of Interspeech 2017 (agosto de 2017): pp. 279-283.
1.  <a id="kurata2017b" style="border-bottom:none">Kurata, Gakuto, Bhuvana Ramabhadran, George Saon e Abhinav Sethy.</a> [*Language Modeling with Highway LSTM.*](https://arxiv.org/pdf/1709.06436.pdf){: external} Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop (ASRU) (2017).
1.  <a id="kurata2019" style="border-bottom:none">Kurata, Gakuto e Kartik Audhkhasi.</a> [*Guiding CTC Posterior Spike Timings for Improved Posterior Fusion and Knowledge Distillation.*](https://arxiv.org/pdf/1904.08311.pdf){: external} Aceito por Interspeech 2019.
1.  <a id="padmanabhan2002" style="border-bottom:none">Padmanabhan, Mukund e Michael Picheny.</a> [*Large-Vocabulary Speech Recognition Algorithms.*](http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=993770&url=http%3A%2F%2Fieeexplore.ieee.org%2Fiel5%2F2%2F21439%2F00993770.pdf%3Farnumber%3D993770){: external} Computer, Vol. 35(4) (2002): pp. 42-50.
1.  <a id="picheny2011" style="border-bottom:none">Picheny, Michael, David Nahamoo, Vaibhava Goel, Brian Kingsbury, Bhuvana Ramabhadran, Steven J. Rennie e George Saon.</a> [*Trends and Advances in Speech Recognition.*](http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=6032775&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D6032775){: external} {{site.data.keyword.IBM_notm}} Journal of Research and Development, Vol. 55(5) (outubro de 2011): pp. 2:1-2:18.
1.  <a id="saon2015" style="border-bottom:none">Saon, George, Hong-Kwang J. Kuo, Steven Rennie e Michael Picheny.</a> [*The {{site.data.keyword.IBM_notm}} 2015 English Conversational Telephone Speech Recognition System.*](https://arxiv.org/pdf/1505.05899.pdf){: external} Enviado ao Interspeech 2015 (2015).
1.  <a id="saon2016" style="border-bottom:none">Saon, George, Tom Sercu, Steven Rennie e Hong-Kwang J. Kuo.</a> [*The {{site.data.keyword.IBM_notm}} 2016 English Conversational Telephone Speech Recognition System.*](https://arxiv.org/pdf/1604.08242v1.pdf){: external} Enviado ao Interspeech 2016 (2016).
1.  <a id="saon2017" style="border-bottom:none">Saon, George, Gakuto Kurata, Tom Sercu, Kartik Audhkhasi, Samuel Thomas, Dimitrios Dimitriadis, Xiaodong Cui, Bhuvana Ramabhadran, Michael Picheny, Lynn-Li Lim, Bergul Roomi e Phil Hall.</a> [*English Conversational Telephone Speech Recognition by Humans and Machines.*](https://www.isca-speech.org/archive/Interspeech_2017/pdfs/0405.PDF){: external} Proceedings of Interspeech 2017 (agosto de 2017): pp. 132-136.
1.  <a id="saon2019" style="border-bottom:none">Saon, George, Zoltan Tuske, Kartik Audhkhasi e Brian Kingsbury.</a> [*Sequence Noise Injected Training for End-to-end Speech Recognition.*](https://ieeexplore.ieee.org/document/8683706){: external} Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (maio de 2019).
1.  <a id="soltau2014" style="border-bottom:none">Soltau, Hagen, George Saon e Tara N. Sainath.</a> [*Joint Training of Convolutional and Non-Convolutional Neural Networks.*](http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=6854669&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D6854669){: external} Proceedings of the IEEE International Conference on Acoustic, Speech and Signal Processing (ICASSP), Florença, Itália (maio 2014): pp. 5572-5576.
1.  <a id="suzuki2019" style="border-bottom:none">Suzuki, Masayuki, Nobuyasu Itoh, Tohru Nagano, Gakuto Kurata e Samuel Thomas.</a> [*Improvements to N-gram Language Model Using Text Generated from Neural Language Model.*](https://ieeexplore.ieee.org/document/8683481){: external} Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (maio de 2019).
1.  <a id="thomas2019" style="border-bottom:none">Thomas, Samuel, Masayuki Suzuki, Yinghui Huang, Gakuto Kurata, Zoltan Tuske, George Saon, Brian Kingsbury e Michael Picheny.</a> [*English Broadcast News Speech Recognition by Humans and Machines.*](https://arxiv.org/pdf/1904.13258.pdf){: external} Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (2019).
